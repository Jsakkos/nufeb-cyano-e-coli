{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from nufeb_tools import utils,plot,spatial\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed, dump,load\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "#%load_ext tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import keras_tuner as kt\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressParallel(Parallel):\n",
    "    def __init__(self, use_tqdm=True, total=None, *args, **kwargs):\n",
    "        self._use_tqdm = use_tqdm\n",
    "        self._total = total\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        with tqdm(disable=not self._use_tqdm, total=self._total) as self._pbar:\n",
    "            return Parallel.__call__(self, *args, **kwargs)\n",
    "\n",
    "    def print_progress(self):\n",
    "        if self._total is None:\n",
    "            self._pbar.total = self.n_dispatched_tasks\n",
    "        self._pbar.n = self.n_completed_tasks\n",
    "        self._pbar.refresh()\n",
    "def collect_data(folder):\n",
    "    \n",
    "    try:\n",
    "        a = utils.get_data(directory=str(folder))\n",
    "        b = spatial.fitness_metrics(a)\n",
    "        return b\n",
    "    except:\n",
    "        print('Error in ' + str(folder))\n",
    "        return\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  #plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [Total Biomass]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = Path(r'E:\\fitness-prediction\\runs')\n",
    "folders = [path for path in DIR.iterdir() if path.is_dir()]\n",
    "if Path(r'E:\\fitness-prediction\\saved-metrics4.pkl').is_file():\n",
    "    data = pd.read_pickle(r'E:\\fitness-prediction\\saved-metrics4.pkl')\n",
    "else:\n",
    "    with ProgressParallel(n_jobs=12) as parallel:\n",
    "        temp = parallel(delayed(collect_data)(folder) for folder in sorted(folders))\n",
    "    data = pd.concat(temp)\n",
    "    data.to_pickle(r'E:\\fitness-prediction\\saved-metrics4.pkl')\n",
    "\n",
    "\n",
    "predictors = list(data.columns.drop(['total biomass','Colony Area','mother_cell'])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mother_cell</th>\n",
       "      <th>type</th>\n",
       "      <th>Voronoi Area</th>\n",
       "      <th>IPTG</th>\n",
       "      <th>Time</th>\n",
       "      <th>Distance from center</th>\n",
       "      <th>total biomass</th>\n",
       "      <th>Nearest 1</th>\n",
       "      <th>Nearest 2</th>\n",
       "      <th>Nearest Neighbor</th>\n",
       "      <th>...</th>\n",
       "      <th>LogNearest 2</th>\n",
       "      <th>LogNearest</th>\n",
       "      <th>Inv1</th>\n",
       "      <th>Inv2</th>\n",
       "      <th>Log Inv1</th>\n",
       "      <th>Log Inv2</th>\n",
       "      <th>Colony Area</th>\n",
       "      <th>initial biomass</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>1.978817e-10</td>\n",
       "      <td>0.36692</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>18725.174159</td>\n",
       "      <td>1.068169e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>6.013393e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.021521</td>\n",
       "      <td>-12.021521</td>\n",
       "      <td>9.361819e+04</td>\n",
       "      <td>166295.456827</td>\n",
       "      <td>22.893960</td>\n",
       "      <td>24.043043</td>\n",
       "      <td>15232.0</td>\n",
       "      <td>178.418964</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>1.943819e-10</td>\n",
       "      <td>0.36692</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>13613.387479</td>\n",
       "      <td>2.400483e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.053653e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.415892</td>\n",
       "      <td>-12.415892</td>\n",
       "      <td>4.165827e+04</td>\n",
       "      <td>246691.090842</td>\n",
       "      <td>21.274511</td>\n",
       "      <td>24.831784</td>\n",
       "      <td>11924.0</td>\n",
       "      <td>309.662175</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4.030559e-10</td>\n",
       "      <td>0.36692</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>7314.070579</td>\n",
       "      <td>2.989025e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.605432e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.288274</td>\n",
       "      <td>-12.288274</td>\n",
       "      <td>3.345573e+04</td>\n",
       "      <td>217134.916354</td>\n",
       "      <td>20.835957</td>\n",
       "      <td>24.576548</td>\n",
       "      <td>6598.0</td>\n",
       "      <td>164.700681</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>7.323750e-10</td>\n",
       "      <td>0.36692</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>12999.941624</td>\n",
       "      <td>1.687371e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>9.452322e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.569250</td>\n",
       "      <td>-11.569250</td>\n",
       "      <td>5.926379e+04</td>\n",
       "      <td>105794.105481</td>\n",
       "      <td>21.979507</td>\n",
       "      <td>23.138500</td>\n",
       "      <td>11925.0</td>\n",
       "      <td>131.594619</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>9.573191e-10</td>\n",
       "      <td>0.36692</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>21866.197226</td>\n",
       "      <td>1.254053e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>6.013393e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.021521</td>\n",
       "      <td>-12.021521</td>\n",
       "      <td>7.974144e+04</td>\n",
       "      <td>166295.456827</td>\n",
       "      <td>22.573089</td>\n",
       "      <td>24.043043</td>\n",
       "      <td>15693.0</td>\n",
       "      <td>213.345049</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.044298e-09</td>\n",
       "      <td>0.02123</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>360743.295668</td>\n",
       "      <td>3.564515e-05</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.577490e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.096772</td>\n",
       "      <td>-12.096772</td>\n",
       "      <td>2.805431e+04</td>\n",
       "      <td>179292.103583</td>\n",
       "      <td>20.483795</td>\n",
       "      <td>24.193543</td>\n",
       "      <td>84957.0</td>\n",
       "      <td>854.539005</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.977255e-09</td>\n",
       "      <td>0.02123</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>535526.268738</td>\n",
       "      <td>1.774832e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.361547e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.603109</td>\n",
       "      <td>-12.603109</td>\n",
       "      <td>5.634336e+04</td>\n",
       "      <td>297482.058654</td>\n",
       "      <td>21.878439</td>\n",
       "      <td>25.206218</td>\n",
       "      <td>118240.0</td>\n",
       "      <td>1266.849913</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3.902051e-09</td>\n",
       "      <td>0.02123</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>332272.304106</td>\n",
       "      <td>8.139410e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.139410e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.489859</td>\n",
       "      <td>-14.021378</td>\n",
       "      <td>1.228590e+06</td>\n",
       "      <td>265629.782806</td>\n",
       "      <td>28.042756</td>\n",
       "      <td>24.979718</td>\n",
       "      <td>72333.0</td>\n",
       "      <td>590.614837</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.02123</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>577973.344035</td>\n",
       "      <td>1.815485e-05</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.195306e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.167755</td>\n",
       "      <td>-12.167755</td>\n",
       "      <td>5.508171e+04</td>\n",
       "      <td>192481.459635</td>\n",
       "      <td>21.833146</td>\n",
       "      <td>24.335510</td>\n",
       "      <td>119251.0</td>\n",
       "      <td>1414.508417</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.140753e-08</td>\n",
       "      <td>0.02123</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>132027.156095</td>\n",
       "      <td>8.139410e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.139410e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.462153</td>\n",
       "      <td>-14.021378</td>\n",
       "      <td>1.228590e+06</td>\n",
       "      <td>258371.194664</td>\n",
       "      <td>28.042756</td>\n",
       "      <td>24.924305</td>\n",
       "      <td>35712.0</td>\n",
       "      <td>509.140454</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48932 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mother_cell  type  Voronoi Area     IPTG       Time  Distance from center  \\\n",
       "0            33     2  1.978817e-10  0.36692  97.222222              0.000042   \n",
       "1            32     2  1.943819e-10  0.36692  97.222222              0.000047   \n",
       "2            20     2  4.030559e-10  0.36692  97.222222              0.000046   \n",
       "3            26     2  7.323750e-10  0.36692  97.222222              0.000035   \n",
       "4            14     2  9.573191e-10  0.36692  97.222222              0.000046   \n",
       "..          ...   ...           ...      ...        ...                   ...   \n",
       "90            3     1  2.044298e-09  0.02123  97.222222              0.000050   \n",
       "91            4     1  6.977255e-09  0.02123  97.222222              0.000013   \n",
       "92            9     1  3.902051e-09  0.02123  97.222222              0.000038   \n",
       "93            5     1  0.000000e+00  0.02123  97.222222              0.000048   \n",
       "94            8     1  1.140753e-08  0.02123  97.222222              0.000037   \n",
       "\n",
       "    total biomass     Nearest 1  Nearest 2  Nearest Neighbor  ...  \\\n",
       "0    18725.174159  1.068169e-05   0.000006      6.013393e-06  ...   \n",
       "1    13613.387479  2.400483e-05   0.000004      4.053653e-06  ...   \n",
       "2     7314.070579  2.989025e-05   0.000005      4.605432e-06  ...   \n",
       "3    12999.941624  1.687371e-05   0.000009      9.452322e-06  ...   \n",
       "4    21866.197226  1.254053e-05   0.000006      6.013393e-06  ...   \n",
       "..            ...           ...        ...               ...  ...   \n",
       "90  360743.295668  3.564515e-05   0.000006      5.577490e-06  ...   \n",
       "91  535526.268738  1.774832e-05   0.000003      3.361547e-06  ...   \n",
       "92  332272.304106  8.139410e-07   0.000004      8.139410e-07  ...   \n",
       "93  577973.344035  1.815485e-05   0.000005      5.195306e-06  ...   \n",
       "94  132027.156095  8.139410e-07   0.000004      8.139410e-07  ...   \n",
       "\n",
       "    LogNearest 2  LogNearest          Inv1           Inv2   Log Inv1  \\\n",
       "0     -12.021521  -12.021521  9.361819e+04  166295.456827  22.893960   \n",
       "1     -12.415892  -12.415892  4.165827e+04  246691.090842  21.274511   \n",
       "2     -12.288274  -12.288274  3.345573e+04  217134.916354  20.835957   \n",
       "3     -11.569250  -11.569250  5.926379e+04  105794.105481  21.979507   \n",
       "4     -12.021521  -12.021521  7.974144e+04  166295.456827  22.573089   \n",
       "..           ...         ...           ...            ...        ...   \n",
       "90    -12.096772  -12.096772  2.805431e+04  179292.103583  20.483795   \n",
       "91    -12.603109  -12.603109  5.634336e+04  297482.058654  21.878439   \n",
       "92    -12.489859  -14.021378  1.228590e+06  265629.782806  28.042756   \n",
       "93    -12.167755  -12.167755  5.508171e+04  192481.459635  21.833146   \n",
       "94    -12.462153  -14.021378  1.228590e+06  258371.194664  28.042756   \n",
       "\n",
       "     Log Inv2  Colony Area  initial biomass         x         y  \n",
       "0   24.043043      15232.0       178.418964  0.000020  0.000021  \n",
       "1   24.831784      11924.0       309.662175  0.000048  0.000097  \n",
       "2   24.576548       6598.0       164.700681  0.000077  0.000087  \n",
       "3   23.138500      11925.0       131.594619  0.000028  0.000077  \n",
       "4   24.043043      15693.0       213.345049  0.000021  0.000015  \n",
       "..        ...          ...              ...       ...       ...  \n",
       "90  24.193543      84957.0       854.539005  0.000085  0.000085  \n",
       "91  25.206218     118240.0      1266.849913  0.000041  0.000060  \n",
       "92  24.979718      72333.0       590.614837  0.000016  0.000034  \n",
       "93  24.335510     119251.0      1414.508417  0.000074  0.000009  \n",
       "94  24.924305      35712.0       509.140454  0.000016  0.000034  \n",
       "\n",
       "[48932 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>Voronoi Area</th>\n",
       "      <th>IPTG</th>\n",
       "      <th>Time</th>\n",
       "      <th>Distance from center</th>\n",
       "      <th>Nearest 1</th>\n",
       "      <th>Nearest 2</th>\n",
       "      <th>Nearest Neighbor</th>\n",
       "      <th>IC1</th>\n",
       "      <th>IC2</th>\n",
       "      <th>...</th>\n",
       "      <th>LogNearest 1</th>\n",
       "      <th>LogNearest 2</th>\n",
       "      <th>LogNearest</th>\n",
       "      <th>Inv1</th>\n",
       "      <th>Inv2</th>\n",
       "      <th>Log Inv1</th>\n",
       "      <th>Log Inv2</th>\n",
       "      <th>initial biomass</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>2.463707e-10</td>\n",
       "      <td>0.07329</td>\n",
       "      <td>84.722222</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.607118</td>\n",
       "      <td>-11.607275</td>\n",
       "      <td>-11.607275</td>\n",
       "      <td>109877.107451</td>\n",
       "      <td>109894.356584</td>\n",
       "      <td>23.214236</td>\n",
       "      <td>23.214550</td>\n",
       "      <td>543.072341</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6.263011e-10</td>\n",
       "      <td>0.20296</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.807297</td>\n",
       "      <td>-10.482317</td>\n",
       "      <td>-11.807297</td>\n",
       "      <td>134228.187919</td>\n",
       "      <td>35678.979174</td>\n",
       "      <td>23.614593</td>\n",
       "      <td>20.964634</td>\n",
       "      <td>1287.282586</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>8.329344e-11</td>\n",
       "      <td>0.26394</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.415702</td>\n",
       "      <td>-11.372085</td>\n",
       "      <td>-11.415702</td>\n",
       "      <td>90735.285586</td>\n",
       "      <td>86862.780223</td>\n",
       "      <td>22.831403</td>\n",
       "      <td>22.744170</td>\n",
       "      <td>111.963357</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>9.241813e-11</td>\n",
       "      <td>0.73644</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.037323</td>\n",
       "      <td>-11.374078</td>\n",
       "      <td>-13.037323</td>\n",
       "      <td>459237.710240</td>\n",
       "      <td>87036.058693</td>\n",
       "      <td>26.074646</td>\n",
       "      <td>22.748156</td>\n",
       "      <td>566.511146</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>2.035042e-11</td>\n",
       "      <td>0.00436</td>\n",
       "      <td>82.777778</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.246461</td>\n",
       "      <td>-12.167455</td>\n",
       "      <td>-12.246461</td>\n",
       "      <td>208242.969706</td>\n",
       "      <td>192423.722360</td>\n",
       "      <td>24.492922</td>\n",
       "      <td>24.334910</td>\n",
       "      <td>749.720358</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>1.648934e-10</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>94.444444</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.527566</td>\n",
       "      <td>-11.260135</td>\n",
       "      <td>-11.527566</td>\n",
       "      <td>101474.795401</td>\n",
       "      <td>77663.045383</td>\n",
       "      <td>23.055131</td>\n",
       "      <td>22.520270</td>\n",
       "      <td>1056.180998</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>2.093778e-11</td>\n",
       "      <td>0.07329</td>\n",
       "      <td>84.722222</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.150481</td>\n",
       "      <td>-11.258861</td>\n",
       "      <td>-12.150481</td>\n",
       "      <td>189185.043470</td>\n",
       "      <td>77564.208608</td>\n",
       "      <td>24.300962</td>\n",
       "      <td>22.517723</td>\n",
       "      <td>498.152194</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>6.273411e-10</td>\n",
       "      <td>0.39249</td>\n",
       "      <td>90.833333</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.181685</td>\n",
       "      <td>-11.904816</td>\n",
       "      <td>-13.181685</td>\n",
       "      <td>530558.109077</td>\n",
       "      <td>147977.574928</td>\n",
       "      <td>26.363370</td>\n",
       "      <td>23.809632</td>\n",
       "      <td>839.002316</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>6.451789e-11</td>\n",
       "      <td>0.01935</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.636006</td>\n",
       "      <td>-12.051190</td>\n",
       "      <td>-12.051190</td>\n",
       "      <td>113097.571077</td>\n",
       "      <td>171303.209366</td>\n",
       "      <td>23.272012</td>\n",
       "      <td>24.102381</td>\n",
       "      <td>103.578116</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>6.152553e-11</td>\n",
       "      <td>0.26394</td>\n",
       "      <td>97.222222</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.122501</td>\n",
       "      <td>-12.243659</td>\n",
       "      <td>-13.122501</td>\n",
       "      <td>500068.764183</td>\n",
       "      <td>207660.249390</td>\n",
       "      <td>26.245002</td>\n",
       "      <td>24.487317</td>\n",
       "      <td>111.619560</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39145 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  Voronoi Area     IPTG       Time  Distance from center  Nearest 1  \\\n",
       "118     1  2.463707e-10  0.07329  84.722222              0.000042   0.000009   \n",
       "5       1  6.263011e-10  0.20296  97.222222              0.000027   0.000007   \n",
       "79      2  8.329344e-11  0.26394  97.222222              0.000054   0.000011   \n",
       "24      1  9.241813e-11  0.73644  88.888889              0.000025   0.000002   \n",
       "125     1  2.035042e-11  0.00436  82.777778              0.000053   0.000005   \n",
       "..    ...           ...      ...        ...                   ...        ...   \n",
       "92      1  1.648934e-10  0.00174  94.444444              0.000035   0.000010   \n",
       "116     1  2.093778e-11  0.07329  84.722222              0.000047   0.000005   \n",
       "61      1  6.273411e-10  0.39249  90.833333              0.000045   0.000002   \n",
       "34      2  6.451789e-11  0.01935  97.222222              0.000044   0.000009   \n",
       "50      2  6.152553e-11  0.26394  97.222222              0.000052   0.000002   \n",
       "\n",
       "     Nearest 2  Nearest Neighbor       IC1       IC2  ...  LogNearest 1  \\\n",
       "118   0.000009          0.000009  0.000006  0.000007  ...    -11.607118   \n",
       "5     0.000028          0.000007  0.000011  0.000032  ...    -11.807297   \n",
       "79    0.000012          0.000011  0.000008  0.000006  ...    -11.415702   \n",
       "24    0.000011          0.000002  0.000006  0.000007  ...    -13.037323   \n",
       "125   0.000005          0.000005  0.000006  0.000007  ...    -12.246461   \n",
       "..         ...               ...       ...       ...  ...           ...   \n",
       "92    0.000013          0.000010  0.000009  0.000007  ...    -11.527566   \n",
       "116   0.000013          0.000005  0.000006  0.000007  ...    -12.150481   \n",
       "61    0.000007          0.000002  0.000006  0.000008  ...    -13.181685   \n",
       "34    0.000006          0.000006  0.000015  0.000006  ...    -11.636006   \n",
       "50    0.000005          0.000002  0.000008  0.000006  ...    -13.122501   \n",
       "\n",
       "     LogNearest 2  LogNearest           Inv1           Inv2   Log Inv1  \\\n",
       "118    -11.607275  -11.607275  109877.107451  109894.356584  23.214236   \n",
       "5      -10.482317  -11.807297  134228.187919   35678.979174  23.614593   \n",
       "79     -11.372085  -11.415702   90735.285586   86862.780223  22.831403   \n",
       "24     -11.374078  -13.037323  459237.710240   87036.058693  26.074646   \n",
       "125    -12.167455  -12.246461  208242.969706  192423.722360  24.492922   \n",
       "..            ...         ...            ...            ...        ...   \n",
       "92     -11.260135  -11.527566  101474.795401   77663.045383  23.055131   \n",
       "116    -11.258861  -12.150481  189185.043470   77564.208608  24.300962   \n",
       "61     -11.904816  -13.181685  530558.109077  147977.574928  26.363370   \n",
       "34     -12.051190  -12.051190  113097.571077  171303.209366  23.272012   \n",
       "50     -12.243659  -13.122501  500068.764183  207660.249390  26.245002   \n",
       "\n",
       "      Log Inv2  initial biomass         x         y  \n",
       "118  23.214550       543.072341  0.000091  0.000063  \n",
       "5    20.964634      1287.282586  0.000025  0.000039  \n",
       "79   22.744170       111.963357  0.000004  0.000020  \n",
       "24   22.748156       566.511146  0.000069  0.000034  \n",
       "125  24.334910       749.720358  0.000010  0.000085  \n",
       "..         ...              ...       ...       ...  \n",
       "92   22.520270      1056.180998  0.000082  0.000035  \n",
       "116  22.517723       498.152194  0.000004  0.000046  \n",
       "61   23.809632       839.002316  0.000072  0.000090  \n",
       "34   24.102381       103.578116  0.000090  0.000067  \n",
       "50   24.487317       111.619560  0.000019  0.000092  \n",
       "\n",
       "[39145 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = list(dataset.columns.drop(['total biomass','Colony Area','mother_cell'])) \n",
    "features = dataset[predictors]\n",
    "labels = dataset['total biomass']\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, train_size = 0.8, random_state = 42)\n",
    "train_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>1.501980</td>\n",
       "      <td>0.500002</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voronoi Area</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>21.508809</td>\n",
       "      <td>2669.148051</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.286170e-11</td>\n",
       "      <td>1.670979e-10</td>\n",
       "      <td>4.152779e-10</td>\n",
       "      <td>4.209812e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPTG</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.153854</td>\n",
       "      <td>0.229670</td>\n",
       "      <td>1.020000e-03</td>\n",
       "      <td>5.930000e-03</td>\n",
       "      <td>3.988000e-02</td>\n",
       "      <td>2.060400e-01</td>\n",
       "      <td>9.880000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>91.253644</td>\n",
       "      <td>5.490597</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>8.666667e+01</td>\n",
       "      <td>9.138889e+01</td>\n",
       "      <td>9.722222e+01</td>\n",
       "      <td>9.722222e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distance from center</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>2.236068e-07</td>\n",
       "      <td>2.740018e-05</td>\n",
       "      <td>3.871860e-05</td>\n",
       "      <td>4.750126e-05</td>\n",
       "      <td>6.887940e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest 1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3.655133e-07</td>\n",
       "      <td>4.835949e-06</td>\n",
       "      <td>7.069180e-06</td>\n",
       "      <td>1.043755e-05</td>\n",
       "      <td>7.908313e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest 2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.920937e-07</td>\n",
       "      <td>4.982971e-06</td>\n",
       "      <td>7.152265e-06</td>\n",
       "      <td>1.028895e-05</td>\n",
       "      <td>8.659224e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbor</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.920937e-07</td>\n",
       "      <td>3.767280e-06</td>\n",
       "      <td>5.303065e-06</td>\n",
       "      <td>7.134101e-06</td>\n",
       "      <td>3.649274e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.294365e-06</td>\n",
       "      <td>6.304458e-06</td>\n",
       "      <td>7.104619e-06</td>\n",
       "      <td>9.252759e-06</td>\n",
       "      <td>3.315020e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>5.303813e-06</td>\n",
       "      <td>6.507337e-06</td>\n",
       "      <td>7.324856e-06</td>\n",
       "      <td>8.827368e-06</td>\n",
       "      <td>4.021472e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.264587e-06</td>\n",
       "      <td>4.992548e-06</td>\n",
       "      <td>5.500426e-06</td>\n",
       "      <td>6.146159e-06</td>\n",
       "      <td>1.484092e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Neighbor Dist 1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.487251</td>\n",
       "      <td>3.277912e-02</td>\n",
       "      <td>6.471937e-01</td>\n",
       "      <td>9.274486e-01</td>\n",
       "      <td>1.267163e+00</td>\n",
       "      <td>4.811610e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Neighbor Dist 2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.999577</td>\n",
       "      <td>0.477643</td>\n",
       "      <td>2.300692e-02</td>\n",
       "      <td>6.553102e-01</td>\n",
       "      <td>9.308108e-01</td>\n",
       "      <td>1.271637e+00</td>\n",
       "      <td>4.360100e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relative Neighbor Dist</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.446011</td>\n",
       "      <td>3.739978e-02</td>\n",
       "      <td>6.778678e-01</td>\n",
       "      <td>9.483014e-01</td>\n",
       "      <td>1.251271e+00</td>\n",
       "      <td>4.062096e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>209.845705</td>\n",
       "      <td>102.385174</td>\n",
       "      <td>6.887817e+00</td>\n",
       "      <td>1.359936e+02</td>\n",
       "      <td>1.948831e+02</td>\n",
       "      <td>2.662666e+02</td>\n",
       "      <td>1.011055e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>825.902448</td>\n",
       "      <td>394.653826</td>\n",
       "      <td>1.900951e+01</td>\n",
       "      <td>5.414513e+02</td>\n",
       "      <td>7.690843e+02</td>\n",
       "      <td>1.050692e+03</td>\n",
       "      <td>3.602541e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z1_2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>825.141288</td>\n",
       "      <td>402.592156</td>\n",
       "      <td>2.708381e+01</td>\n",
       "      <td>5.347451e+02</td>\n",
       "      <td>7.663063e+02</td>\n",
       "      <td>1.046996e+03</td>\n",
       "      <td>3.975602e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z2_1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>210.039279</td>\n",
       "      <td>100.366339</td>\n",
       "      <td>4.834401e+00</td>\n",
       "      <td>1.376991e+02</td>\n",
       "      <td>1.955896e+02</td>\n",
       "      <td>2.672067e+02</td>\n",
       "      <td>9.161798e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogNearest 1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>-11.850015</td>\n",
       "      <td>0.637249</td>\n",
       "      <td>-1.482196e+01</td>\n",
       "      <td>-1.223943e+01</td>\n",
       "      <td>-1.185977e+01</td>\n",
       "      <td>-1.147010e+01</td>\n",
       "      <td>-9.445011e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogNearest 2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>-11.847681</td>\n",
       "      <td>0.611137</td>\n",
       "      <td>-1.546528e+01</td>\n",
       "      <td>-1.220948e+01</td>\n",
       "      <td>-1.184808e+01</td>\n",
       "      <td>-1.148444e+01</td>\n",
       "      <td>-9.354300e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogNearest</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>-12.193428</td>\n",
       "      <td>0.517113</td>\n",
       "      <td>-1.546528e+01</td>\n",
       "      <td>-1.248916e+01</td>\n",
       "      <td>-1.214723e+01</td>\n",
       "      <td>-1.185062e+01</td>\n",
       "      <td>-1.021840e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inv1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>172483.973194</td>\n",
       "      <td>136919.824106</td>\n",
       "      <td>1.264492e+04</td>\n",
       "      <td>9.580790e+04</td>\n",
       "      <td>1.414591e+05</td>\n",
       "      <td>2.067847e+05</td>\n",
       "      <td>2.735878e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inv2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>169901.790024</td>\n",
       "      <td>139498.463955</td>\n",
       "      <td>1.154838e+04</td>\n",
       "      <td>9.719164e+04</td>\n",
       "      <td>1.398158e+05</td>\n",
       "      <td>2.006835e+05</td>\n",
       "      <td>5.205792e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Inv1</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>23.700031</td>\n",
       "      <td>1.274497</td>\n",
       "      <td>1.889002e+01</td>\n",
       "      <td>2.294020e+01</td>\n",
       "      <td>2.371953e+01</td>\n",
       "      <td>2.447887e+01</td>\n",
       "      <td>2.964393e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Inv2</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>23.695362</td>\n",
       "      <td>1.222274</td>\n",
       "      <td>1.870860e+01</td>\n",
       "      <td>2.296888e+01</td>\n",
       "      <td>2.369616e+01</td>\n",
       "      <td>2.441897e+01</td>\n",
       "      <td>3.093056e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial biomass</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>578.149393</td>\n",
       "      <td>424.428267</td>\n",
       "      <td>8.206812e+01</td>\n",
       "      <td>2.029399e+02</td>\n",
       "      <td>3.234230e+02</td>\n",
       "      <td>9.518031e+02</td>\n",
       "      <td>1.414508e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>9.770000e-07</td>\n",
       "      <td>2.570000e-05</td>\n",
       "      <td>4.980000e-05</td>\n",
       "      <td>7.420000e-05</td>\n",
       "      <td>9.910000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>39145.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>1.040000e-06</td>\n",
       "      <td>2.550000e-05</td>\n",
       "      <td>4.940000e-05</td>\n",
       "      <td>7.400000e-05</td>\n",
       "      <td>9.910000e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count           mean            std           min  \\\n",
       "type                      39145.0       1.501980       0.500002  1.000000e+00   \n",
       "Voronoi Area              39145.0      21.508809    2669.148051  0.000000e+00   \n",
       "IPTG                      39145.0       0.153854       0.229670  1.020000e-03   \n",
       "Time                      39145.0      91.253644       5.490597  8.000000e+01   \n",
       "Distance from center      39145.0       0.000037       0.000014  2.236068e-07   \n",
       "Nearest 1                 39145.0       0.000009       0.000007  3.655133e-07   \n",
       "Nearest 2                 39145.0       0.000009       0.000006  1.920937e-07   \n",
       "Nearest Neighbor          39145.0       0.000006       0.000003  1.920937e-07   \n",
       "IC1                       39145.0       0.000009       0.000004  5.294365e-06   \n",
       "IC2                       39145.0       0.000009       0.000004  5.303813e-06   \n",
       "IC                        39145.0       0.000006       0.000001  4.264587e-06   \n",
       "Relative Neighbor Dist 1  39145.0       0.998656       0.487251  3.277912e-02   \n",
       "Relative Neighbor Dist 2  39145.0       0.999577       0.477643  2.300692e-02   \n",
       "Relative Neighbor Dist    39145.0       0.999784       0.446011  3.739978e-02   \n",
       "Z1                        39145.0     209.845705     102.385174  6.887817e+00   \n",
       "Z2                        39145.0     825.902448     394.653826  1.900951e+01   \n",
       "Z1_2                      39145.0     825.141288     402.592156  2.708381e+01   \n",
       "Z2_1                      39145.0     210.039279     100.366339  4.834401e+00   \n",
       "LogNearest 1              39145.0     -11.850015       0.637249 -1.482196e+01   \n",
       "LogNearest 2              39145.0     -11.847681       0.611137 -1.546528e+01   \n",
       "LogNearest                39145.0     -12.193428       0.517113 -1.546528e+01   \n",
       "Inv1                      39145.0  172483.973194  136919.824106  1.264492e+04   \n",
       "Inv2                      39145.0  169901.790024  139498.463955  1.154838e+04   \n",
       "Log Inv1                  39145.0      23.700031       1.274497  1.889002e+01   \n",
       "Log Inv2                  39145.0      23.695362       1.222274  1.870860e+01   \n",
       "initial biomass           39145.0     578.149393     424.428267  8.206812e+01   \n",
       "x                         39145.0       0.000050       0.000028  9.770000e-07   \n",
       "y                         39145.0       0.000050       0.000028  1.040000e-06   \n",
       "\n",
       "                                   25%           50%           75%  \\\n",
       "type                      1.000000e+00  2.000000e+00  2.000000e+00   \n",
       "Voronoi Area              9.286170e-11  1.670979e-10  4.152779e-10   \n",
       "IPTG                      5.930000e-03  3.988000e-02  2.060400e-01   \n",
       "Time                      8.666667e+01  9.138889e+01  9.722222e+01   \n",
       "Distance from center      2.740018e-05  3.871860e-05  4.750126e-05   \n",
       "Nearest 1                 4.835949e-06  7.069180e-06  1.043755e-05   \n",
       "Nearest 2                 4.982971e-06  7.152265e-06  1.028895e-05   \n",
       "Nearest Neighbor          3.767280e-06  5.303065e-06  7.134101e-06   \n",
       "IC1                       6.304458e-06  7.104619e-06  9.252759e-06   \n",
       "IC2                       6.507337e-06  7.324856e-06  8.827368e-06   \n",
       "IC                        4.992548e-06  5.500426e-06  6.146159e-06   \n",
       "Relative Neighbor Dist 1  6.471937e-01  9.274486e-01  1.267163e+00   \n",
       "Relative Neighbor Dist 2  6.553102e-01  9.308108e-01  1.271637e+00   \n",
       "Relative Neighbor Dist    6.778678e-01  9.483014e-01  1.251271e+00   \n",
       "Z1                        1.359936e+02  1.948831e+02  2.662666e+02   \n",
       "Z2                        5.414513e+02  7.690843e+02  1.050692e+03   \n",
       "Z1_2                      5.347451e+02  7.663063e+02  1.046996e+03   \n",
       "Z2_1                      1.376991e+02  1.955896e+02  2.672067e+02   \n",
       "LogNearest 1             -1.223943e+01 -1.185977e+01 -1.147010e+01   \n",
       "LogNearest 2             -1.220948e+01 -1.184808e+01 -1.148444e+01   \n",
       "LogNearest               -1.248916e+01 -1.214723e+01 -1.185062e+01   \n",
       "Inv1                      9.580790e+04  1.414591e+05  2.067847e+05   \n",
       "Inv2                      9.719164e+04  1.398158e+05  2.006835e+05   \n",
       "Log Inv1                  2.294020e+01  2.371953e+01  2.447887e+01   \n",
       "Log Inv2                  2.296888e+01  2.369616e+01  2.441897e+01   \n",
       "initial biomass           2.029399e+02  3.234230e+02  9.518031e+02   \n",
       "x                         2.570000e-05  4.980000e-05  7.420000e-05   \n",
       "y                         2.550000e-05  4.940000e-05  7.400000e-05   \n",
       "\n",
       "                                   max  \n",
       "type                      2.000000e+00  \n",
       "Voronoi Area              4.209812e+05  \n",
       "IPTG                      9.880000e-01  \n",
       "Time                      9.722222e+01  \n",
       "Distance from center      6.887940e-05  \n",
       "Nearest 1                 7.908313e-05  \n",
       "Nearest 2                 8.659224e-05  \n",
       "Nearest Neighbor          3.649274e-05  \n",
       "IC1                       3.315020e-05  \n",
       "IC2                       4.021472e-05  \n",
       "IC                        1.484092e-05  \n",
       "Relative Neighbor Dist 1  4.811610e+00  \n",
       "Relative Neighbor Dist 2  4.360100e+00  \n",
       "Relative Neighbor Dist    4.062096e+00  \n",
       "Z1                        1.011055e+03  \n",
       "Z2                        3.602541e+03  \n",
       "Z1_2                      3.975602e+03  \n",
       "Z2_1                      9.161798e+02  \n",
       "LogNearest 1             -9.445011e+00  \n",
       "LogNearest 2             -9.354300e+00  \n",
       "LogNearest               -1.021840e+01  \n",
       "Inv1                      2.735878e+06  \n",
       "Inv2                      5.205792e+06  \n",
       "Log Inv1                  2.964393e+01  \n",
       "Log Inv2                  3.093056e+01  \n",
       "initial biomass           1.414508e+03  \n",
       "x                         9.910000e-05  \n",
       "y                         9.910000e-05  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe().transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     1.502     21.509      0.154     91.254      0.         0.\n",
      "       0.         0.         0.         0.         0.         0.999\n",
      "       1.         1.       209.846    825.902    825.141    210.039\n",
      "     -11.85     -11.848    -12.193 172484.1   169901.55      23.7\n",
      "      23.695    578.149      0.         0.   ]]\n"
     ]
    }
   ],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "print(normalizer.mean.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example: [[     1.        0.        0.07     84.72      0.        0.        0.\n",
      "       0.        0.        0.        0.        1.54      1.3       1.88\n",
      "     323.95   1072.29   1273.8     272.7     -11.61    -11.61    -11.61\n",
      "  109877.11 109894.36     23.21     23.21    543.07      0.        0.  ]]\n",
      "\n",
      "Normalized: [[-1.   -0.01 -0.35 -1.19  0.38  0.05  0.07  1.2  -0.65 -0.4  -0.86  1.11\n",
      "   0.62  1.98  1.11  0.62  1.11  0.62  0.38  0.39  1.13 -0.46 -0.43 -0.38\n",
      "  -0.39 -0.08  1.45  0.45]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(train_features[:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_NUM_UNITS1 = hp.HParam('units1', hp.IntInterval(32, 64))\n",
    "# HP_NUM_UNITS2 = hp.HParam('units2', hp.IntInterval(32, 64))\n",
    "# HP_L2 = hp.HParam('l2_rate', hp.RealInterval(0.0, 0.2))\n",
    "# # HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# # HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([3e-1, 1e-1, 1e-2]))\n",
    "\n",
    "# MSE = 'mean_squared_error'\n",
    "# logdir = 'D:/nufeb-cyano-e-coli/logs/test/'\n",
    "# #tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "# tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "#                          histogram_freq=1,\n",
    "#                          write_graph=True,\n",
    "#                          update_freq='epoch',\n",
    "#                          embeddings_freq=1)\n",
    "# stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "# l2=0.1\n",
    "# model = None\n",
    "# model = keras.Sequential(normalizer)\n",
    "# model.add(keras.layers.Dense(units=64, activation=\"relu\",kernel_regularizer=keras.regularizers.l2(l2)))\n",
    "# model.add(keras.layers.Dense(units=64, activation='relu',kernel_regularizer=keras.regularizers.l2(l2)))\n",
    "# model.add(keras.layers.Dense(1))\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=.3),\n",
    "#               loss='mean_squared_error',\n",
    "#               metrics=['mean_squared_error'])\n",
    "\n",
    "# model.fit(train_features, train_labels, epochs=1000, validation_split=0.2,callbacks=[tensorboard_callback,\n",
    "# stop_early,\n",
    "# hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "# ],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# with tf.summary.create_file_writer(logdir).as_default():\n",
    "#   hp.hparams_config(\n",
    "#     hparams=[HP_NUM_UNITS1, HP_NUM_UNITS2,HP_L2,HP_DROPOUT, HP_OPTIMIZER,HP_LEARNING_RATE],\n",
    "#     metrics=[hp.Metric(MSE, display_name='mean_squared_error')],\n",
    "#   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP_NUM_UNITS1 = hp.HParam('units1', hp.IntInterval(32, 128))\n",
    "# HP_NUM_UNITS2 = hp.HParam('units2', hp.IntInterval(32, 128))\n",
    "# HP_L2 = hp.HParam('l2_rate', hp.RealInterval(0.0, 0.2))\n",
    "# # HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "# # HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "# HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([3e-1, 1e-1, 1e-2]))\n",
    "\n",
    "# MSE = 'mean_squared_error'\n",
    "# logdir = \"D:/nufeb-cyano-e-coli/logs/hparam_tuning/\"\n",
    "\n",
    "# def train_test_model(hparams):\n",
    "#   tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir,\n",
    "#                         histogram_freq=1,\n",
    "#                         write_graph=True,\n",
    "#                         write_images=True,\n",
    "#                         update_freq='epoch',\n",
    "#                         profile_batch=2,\n",
    "#                         embeddings_freq=1)\n",
    "#   stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "#   model = tf.keras.models.Sequential([\n",
    "#     normalizer,\n",
    "#     keras.layers.Dense(hparams[HP_NUM_UNITS1], activation='relu',kernel_regularizer=keras.regularizers.l2(hparams[HP_L2])),\n",
    "#     keras.layers.Dense(hparams[HP_NUM_UNITS2], activation='relu',kernel_regularizer=keras.regularizers.l2(hparams[HP_L2])),\n",
    "#     #keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "#     keras.layers.Dense(1),\n",
    "#   ])\n",
    "#   model.compile(\n",
    "#       optimizer=keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING_RATE]),\n",
    "#       loss='mean_squared_error',\n",
    "#       metrics=['mean_squared_error']\n",
    "#   )\n",
    "\n",
    "#   model.fit(train_features, train_labels, epochs=100, validation_split=0.2,\n",
    "#   callbacks=[tensorboard_callback,stop_early,hp.KerasCallback(logdir, hparams)]\n",
    "#   )\n",
    "#   _, mse = model.evaluate(test_features, test_labels)\n",
    "#   test_predictions  = model.predict(test_features).flatten()\n",
    "#   r2=r2_score(test_labels, test_predictions)\n",
    "#   return r2,mse\n",
    "# def run(run_dir, hparams):\n",
    "#   with tf.summary.create_file_writer(run_dir).as_default():\n",
    "#     hp.hparams(hparams)  # record the values used in this trial\n",
    "#     r2,mse = train_test_model(hparams)\n",
    "#     tf.summary.scalar(MSE, mse, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #session_num = 0\n",
    "# for num_units1 in np.arange(HP_NUM_UNITS1.domain.min_value,HP_NUM_UNITS1.domain.max_value,32):\n",
    "#   for num_units2 in np.arange(HP_NUM_UNITS2.domain.min_value,HP_NUM_UNITS2.domain.max_value,32):\n",
    "#     for l2_rate in np.linspace(HP_L2.domain.min_value,HP_L2.domain.max_value,10):\n",
    "#         for learning_rate in HP_LEARNING_RATE.domain.values:\n",
    "#           hparams = {\n",
    "#               HP_NUM_UNITS1: num_units1,\n",
    "#               HP_NUM_UNITS2: num_units2,\n",
    "#               HP_L2: l2_rate,\n",
    "#               HP_LEARNING_RATE: learning_rate,\n",
    "#           }\n",
    "#           #run_name = \"run-%d\" % session_num\n",
    "#           #print('--- Starting trial: %s' % run_name)\n",
    "#           print({h.name: hparams[h] for h in hparams})\n",
    "#           hp.hparams(hparams)  # record the values used in this trial\n",
    "#           r2,mse = train_test_model(hparams)\n",
    "#           #tf.summary.scalar(MSE, mse, step=1)\n",
    "#           #run(logdir + run_name, hparams)\n",
    "#           #session_num += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ../logs\\HPO\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ../logs\\HPO\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "  model = None\n",
    "  model = keras.Sequential(normalizer)\n",
    "  #l2r = hp.Float(\"L2_rate\", min_value=1e-4, max_value=5e-1, sampling=\"log\")\n",
    "  #,kernel_regularizer=keras.regularizers.l2(l2r)\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  model.add(keras.layers.Dense(units=hp.Int(\"Depth1\", min_value=32, max_value=512, step=32), activation=\"relu\"))\n",
    "  model.add(keras.layers.Dense(units=hp.Int(\"Depth2\", min_value=32, max_value=512, step=32), activation='relu'))\n",
    "  #keras.layers.Dropout(hp.Float(\"Dropout\", min_value=0, max_value=5e-1, sampling='linear')),\n",
    "  model.add(keras.layers.Dense(1))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  learning_rate = hp.Float(\"Learning_Rate\", min_value=1e-4, max_value=5e-1, sampling=\"log\")\n",
    "  #learning_rate = hp.Choice('Learning_Rate', values=[5e-1, 3e-1, 1e-1,1e-2])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                loss='mean_squared_error',\n",
    "                metrics=['mean_squared_error'])\n",
    "\n",
    "  return model\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_mean_squared_error',\n",
    "                     max_epochs=1000,\n",
    "                     factor=3,\n",
    "                     directory='../logs',\n",
    "                     project_name='HPO')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1251 Complete [00h 02m 27s]\n",
      "val_mean_squared_error: 1037826176.0\n",
      "\n",
      "Best val_mean_squared_error So Far: 985645888.0\n",
      "Total elapsed time: 00h 41m 30s\n",
      "\n",
      "Search: Running Trial #1252\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "384               |256               |Depth1\n",
      "352               |256               |Depth2\n",
      "0.1434            |0.073102          |Learning_Rate\n",
      "1000              |38                |tuner/epochs\n",
      "334               |13                |tuner/initial_epoch\n",
      "6                 |6                 |tuner/bracket\n",
      "6                 |3                 |tuner/round\n",
      "1247              |1160              |tuner/trial_id\n",
      "\n",
      "Epoch 335/1000\n",
      "  5/979 [..............................] - ETA: 13s - loss: 29020706816.0000 - mean_squared_error: 29020706816.0000  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0100s). Check your callbacks.\n",
      "979/979 [==============================] - 11s 11ms/step - loss: 25441294336.0000 - mean_squared_error: 25441294336.0000 - val_loss: 1959452416.0000 - val_mean_squared_error: 1959452416.0000\n",
      "Epoch 336/1000\n",
      "979/979 [==============================] - 11s 11ms/step - loss: 1657245568.0000 - mean_squared_error: 1657245568.0000 - val_loss: 1663895424.0000 - val_mean_squared_error: 1663895424.0000\n",
      "Epoch 337/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1400434560.0000 - mean_squared_error: 1400434560.0000 - val_loss: 1384757504.0000 - val_mean_squared_error: 1384757504.0000\n",
      "Epoch 338/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1300228352.0000 - mean_squared_error: 1300228352.0000 - val_loss: 1254133376.0000 - val_mean_squared_error: 1254133376.0000\n",
      "Epoch 339/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1245291392.0000 - mean_squared_error: 1245291392.0000 - val_loss: 1182183424.0000 - val_mean_squared_error: 1182183424.0000\n",
      "Epoch 340/1000\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1200113920.0000 - mean_squared_error: 1200113920.0000 - val_loss: 1283031040.0000 - val_mean_squared_error: 1283031040.0000\n",
      "Epoch 341/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1182251008.0000 - mean_squared_error: 1182251008.0000 - val_loss: 1180355200.0000 - val_mean_squared_error: 1180355200.0000\n",
      "Epoch 342/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1128488960.0000 - mean_squared_error: 1128488960.0000 - val_loss: 1109802240.0000 - val_mean_squared_error: 1109802240.0000\n",
      "Epoch 343/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1117579520.0000 - mean_squared_error: 1117579520.0000 - val_loss: 1178694144.0000 - val_mean_squared_error: 1178694144.0000\n",
      "Epoch 344/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1089128192.0000 - mean_squared_error: 1089128192.0000 - val_loss: 1130573184.0000 - val_mean_squared_error: 1130573184.0000\n",
      "Epoch 345/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1058935296.0000 - mean_squared_error: 1058935296.0000 - val_loss: 1077355776.0000 - val_mean_squared_error: 1077355776.0000\n",
      "Epoch 346/1000\n",
      "979/979 [==============================] - 11s 12ms/step - loss: 1069950656.0000 - mean_squared_error: 1069950656.0000 - val_loss: 1133013888.0000 - val_mean_squared_error: 1133013888.0000\n",
      "Epoch 347/1000\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 1059046016.0000 - mean_squared_error: 1059046016.0000 - val_loss: 1108757248.0000 - val_mean_squared_error: 1108757248.0000\n",
      "Epoch 348/1000\n",
      "266/979 [=======>......................] - ETA: 6s - loss: 1017720832.0000 - mean_squared_error: 1017720832.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25892\\1885879762.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../logs/HPO/tb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get the optimal hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]09\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[0;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HyperModel.fit()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(train_features, train_labels,epochs=1000, validation_split=0.2,callbacks=[keras.callbacks.TensorBoard('../logs/HPO/tb'),stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "#09\n",
    "\n",
    "# print(f\"\"\"\n",
    "# The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "# layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "# is {best_hps.get('learning_rate')}.\n",
    "# \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'space': [{'class_name': 'Int',\n",
       "   'config': {'name': 'Depth1',\n",
       "    'default': None,\n",
       "    'conditions': [],\n",
       "    'min_value': 32,\n",
       "    'max_value': 512,\n",
       "    'step': 32,\n",
       "    'sampling': None}},\n",
       "  {'class_name': 'Int',\n",
       "   'config': {'name': 'Depth2',\n",
       "    'default': None,\n",
       "    'conditions': [],\n",
       "    'min_value': 32,\n",
       "    'max_value': 512,\n",
       "    'step': 32,\n",
       "    'sampling': None}},\n",
       "  {'class_name': 'Float',\n",
       "   'config': {'name': 'Learning_Rate',\n",
       "    'default': 0.0001,\n",
       "    'conditions': [],\n",
       "    'min_value': 0.0001,\n",
       "    'max_value': 0.5,\n",
       "    'step': None,\n",
       "    'sampling': 'log'}}],\n",
       " 'values': {'Depth1': 256,\n",
       "  'Depth2': 256,\n",
       "  'Learning_Rate': 0.0731016779286539,\n",
       "  'tuner/epochs': 38,\n",
       "  'tuner/initial_epoch': 13,\n",
       "  'tuner/bracket': 6,\n",
       "  'tuner/round': 3,\n",
       "  'tuner/trial_id': '1160'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 5497868288.0000 - mean_squared_error: 5497868288.0000 - val_loss: 1991423872.0000 - val_mean_squared_error: 1991423872.0000\n",
      "Epoch 2/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1599493504.0000 - mean_squared_error: 1599493504.0000 - val_loss: 1468748928.0000 - val_mean_squared_error: 1468748928.0000\n",
      "Epoch 3/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 1335255168.0000 - mean_squared_error: 1335255168.0000 - val_loss: 1300213888.0000 - val_mean_squared_error: 1300213888.0000\n",
      "Epoch 4/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 1269650048.0000 - mean_squared_error: 1269650048.0000 - val_loss: 1283832576.0000 - val_mean_squared_error: 1283832576.0000\n",
      "Epoch 5/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1222205440.0000 - mean_squared_error: 1222205440.0000 - val_loss: 1202755456.0000 - val_mean_squared_error: 1202755456.0000\n",
      "Epoch 6/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1230977280.0000 - mean_squared_error: 1230977280.0000 - val_loss: 1210698624.0000 - val_mean_squared_error: 1210698624.0000\n",
      "Epoch 7/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1178622592.0000 - mean_squared_error: 1178622592.0000 - val_loss: 1267292160.0000 - val_mean_squared_error: 1267292160.0000\n",
      "Epoch 8/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1161881984.0000 - mean_squared_error: 1161881984.0000 - val_loss: 1126607232.0000 - val_mean_squared_error: 1126607232.0000\n",
      "Epoch 9/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1157258368.0000 - mean_squared_error: 1157258368.0000 - val_loss: 1172699648.0000 - val_mean_squared_error: 1172699648.0000\n",
      "Epoch 10/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1152664448.0000 - mean_squared_error: 1152664448.0000 - val_loss: 1154247296.0000 - val_mean_squared_error: 1154247296.0000\n",
      "Epoch 11/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1144153472.0000 - mean_squared_error: 1144153472.0000 - val_loss: 1138936064.0000 - val_mean_squared_error: 1138936064.0000\n",
      "Epoch 12/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1135601920.0000 - mean_squared_error: 1135601920.0000 - val_loss: 1400457728.0000 - val_mean_squared_error: 1400457728.0000\n",
      "Epoch 13/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1110020096.0000 - mean_squared_error: 1110020096.0000 - val_loss: 1175659904.0000 - val_mean_squared_error: 1175659904.0000\n",
      "Epoch 14/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1088981888.0000 - mean_squared_error: 1088981888.0000 - val_loss: 1344378496.0000 - val_mean_squared_error: 1344378496.0000\n",
      "Epoch 15/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1085524224.0000 - mean_squared_error: 1085524224.0000 - val_loss: 1289279616.0000 - val_mean_squared_error: 1289279616.0000\n",
      "Epoch 16/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1077555968.0000 - mean_squared_error: 1077555968.0000 - val_loss: 1144676096.0000 - val_mean_squared_error: 1144676096.0000\n",
      "Epoch 17/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1083316864.0000 - mean_squared_error: 1083316864.0000 - val_loss: 1131517184.0000 - val_mean_squared_error: 1131517184.0000\n",
      "Epoch 18/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1087387392.0000 - mean_squared_error: 1087387392.0000 - val_loss: 1179603584.0000 - val_mean_squared_error: 1179603584.0000\n",
      "Epoch 19/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1060915328.0000 - mean_squared_error: 1060915328.0000 - val_loss: 1048020224.0000 - val_mean_squared_error: 1048020224.0000\n",
      "Epoch 20/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1052876416.0000 - mean_squared_error: 1052876416.0000 - val_loss: 1130120064.0000 - val_mean_squared_error: 1130120064.0000\n",
      "Epoch 21/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1065368128.0000 - mean_squared_error: 1065368128.0000 - val_loss: 1124884864.0000 - val_mean_squared_error: 1124884864.0000\n",
      "Epoch 22/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1063261824.0000 - mean_squared_error: 1063261824.0000 - val_loss: 1246762368.0000 - val_mean_squared_error: 1246762368.0000\n",
      "Epoch 23/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1030598912.0000 - mean_squared_error: 1030598912.0000 - val_loss: 1125474176.0000 - val_mean_squared_error: 1125474176.0000\n",
      "Epoch 24/100\n",
      "979/979 [==============================] - 8s 9ms/step - loss: 1035817664.0000 - mean_squared_error: 1035817664.0000 - val_loss: 1154067328.0000 - val_mean_squared_error: 1154067328.0000\n",
      "Epoch 25/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1038812032.0000 - mean_squared_error: 1038812032.0000 - val_loss: 1074509312.0000 - val_mean_squared_error: 1074509312.0000\n",
      "Epoch 26/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1020347584.0000 - mean_squared_error: 1020347584.0000 - val_loss: 1287728768.0000 - val_mean_squared_error: 1287728768.0000\n",
      "Epoch 27/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1030995136.0000 - mean_squared_error: 1030995136.0000 - val_loss: 1055028736.0000 - val_mean_squared_error: 1055028736.0000\n",
      "Epoch 28/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1022774336.0000 - mean_squared_error: 1022774336.0000 - val_loss: 1083630208.0000 - val_mean_squared_error: 1083630208.0000\n",
      "Epoch 29/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1001357056.0000 - mean_squared_error: 1001357056.0000 - val_loss: 1172163456.0000 - val_mean_squared_error: 1172163456.0000\n",
      "Epoch 30/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1032472704.0000 - mean_squared_error: 1032472704.0000 - val_loss: 1035726912.0000 - val_mean_squared_error: 1035726912.0000\n",
      "Epoch 31/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 1019583808.0000 - mean_squared_error: 1019583808.0000 - val_loss: 1136383744.0000 - val_mean_squared_error: 1136383744.0000\n",
      "Epoch 32/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 996757376.0000 - mean_squared_error: 996757376.0000 - val_loss: 1154827008.0000 - val_mean_squared_error: 1154827008.0000\n",
      "Epoch 33/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 998344832.0000 - mean_squared_error: 998344832.0000 - val_loss: 1081334528.0000 - val_mean_squared_error: 1081334528.0000\n",
      "Epoch 34/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 985395904.0000 - mean_squared_error: 985395904.0000 - val_loss: 1069602432.0000 - val_mean_squared_error: 1069602432.0000\n",
      "Epoch 35/100\n",
      "979/979 [==============================] - 7s 8ms/step - loss: 991815296.0000 - mean_squared_error: 991815296.0000 - val_loss: 1128577024.0000 - val_mean_squared_error: 1128577024.0000\n",
      "Epoch 36/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 986689536.0000 - mean_squared_error: 986689536.0000 - val_loss: 1147176576.0000 - val_mean_squared_error: 1147176576.0000\n",
      "Epoch 37/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 958066176.0000 - mean_squared_error: 958066176.0000 - val_loss: 1016908480.0000 - val_mean_squared_error: 1016908480.0000\n",
      "Epoch 38/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 959671744.0000 - mean_squared_error: 959671744.0000 - val_loss: 1393928064.0000 - val_mean_squared_error: 1393928064.0000\n",
      "Epoch 39/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 974033408.0000 - mean_squared_error: 974033408.0000 - val_loss: 1068792256.0000 - val_mean_squared_error: 1068792256.0000\n",
      "Epoch 40/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 958963968.0000 - mean_squared_error: 958963968.0000 - val_loss: 999091648.0000 - val_mean_squared_error: 999091648.0000\n",
      "Epoch 41/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 933338304.0000 - mean_squared_error: 933338304.0000 - val_loss: 1238022784.0000 - val_mean_squared_error: 1238022784.0000\n",
      "Epoch 42/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 951904640.0000 - mean_squared_error: 951904640.0000 - val_loss: 1052937920.0000 - val_mean_squared_error: 1052937920.0000\n",
      "Epoch 43/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 928324800.0000 - mean_squared_error: 928324800.0000 - val_loss: 1009377792.0000 - val_mean_squared_error: 1009377792.0000\n",
      "Epoch 44/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 932263424.0000 - mean_squared_error: 932263424.0000 - val_loss: 1036229056.0000 - val_mean_squared_error: 1036229056.0000\n",
      "Epoch 45/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 933863616.0000 - mean_squared_error: 933863616.0000 - val_loss: 1057637120.0000 - val_mean_squared_error: 1057637120.0000\n",
      "Epoch 46/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 930244480.0000 - mean_squared_error: 930244480.0000 - val_loss: 1083979392.0000 - val_mean_squared_error: 1083979392.0000\n",
      "Epoch 47/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 916730304.0000 - mean_squared_error: 916730304.0000 - val_loss: 1128129792.0000 - val_mean_squared_error: 1128129792.0000\n",
      "Epoch 48/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 924127104.0000 - mean_squared_error: 924127104.0000 - val_loss: 1075700608.0000 - val_mean_squared_error: 1075700608.0000\n",
      "Epoch 49/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 940172032.0000 - mean_squared_error: 940172032.0000 - val_loss: 1072059328.0000 - val_mean_squared_error: 1072059328.0000\n",
      "Epoch 50/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 919960000.0000 - mean_squared_error: 919960000.0000 - val_loss: 1174148608.0000 - val_mean_squared_error: 1174148608.0000\n",
      "Epoch 51/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 914547392.0000 - mean_squared_error: 914547392.0000 - val_loss: 1088934528.0000 - val_mean_squared_error: 1088934528.0000\n",
      "Epoch 52/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 911067520.0000 - mean_squared_error: 911067520.0000 - val_loss: 1045027456.0000 - val_mean_squared_error: 1045027456.0000\n",
      "Epoch 53/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 918580288.0000 - mean_squared_error: 918580288.0000 - val_loss: 1025344256.0000 - val_mean_squared_error: 1025344256.0000\n",
      "Epoch 54/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 902831616.0000 - mean_squared_error: 902831616.0000 - val_loss: 1074142464.0000 - val_mean_squared_error: 1074142464.0000\n",
      "Epoch 55/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 903310592.0000 - mean_squared_error: 903310592.0000 - val_loss: 1013639936.0000 - val_mean_squared_error: 1013639936.0000\n",
      "Epoch 56/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 928588096.0000 - mean_squared_error: 928588096.0000 - val_loss: 1073086400.0000 - val_mean_squared_error: 1073086400.0000\n",
      "Epoch 57/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 906810944.0000 - mean_squared_error: 906810944.0000 - val_loss: 1000455424.0000 - val_mean_squared_error: 1000455424.0000\n",
      "Epoch 58/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 889998080.0000 - mean_squared_error: 889998080.0000 - val_loss: 998180992.0000 - val_mean_squared_error: 998180992.0000\n",
      "Epoch 59/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 902353536.0000 - mean_squared_error: 902353536.0000 - val_loss: 1003657152.0000 - val_mean_squared_error: 1003657152.0000\n",
      "Epoch 60/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 897998464.0000 - mean_squared_error: 897998464.0000 - val_loss: 1007069504.0000 - val_mean_squared_error: 1007069504.0000\n",
      "Epoch 61/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 894806976.0000 - mean_squared_error: 894806976.0000 - val_loss: 1022204160.0000 - val_mean_squared_error: 1022204160.0000\n",
      "Epoch 62/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 906124544.0000 - mean_squared_error: 906124544.0000 - val_loss: 1061717312.0000 - val_mean_squared_error: 1061717312.0000\n",
      "Epoch 63/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 903905536.0000 - mean_squared_error: 903905536.0000 - val_loss: 999695104.0000 - val_mean_squared_error: 999695104.0000\n",
      "Epoch 64/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 883665408.0000 - mean_squared_error: 883665408.0000 - val_loss: 1038656384.0000 - val_mean_squared_error: 1038656384.0000\n",
      "Epoch 65/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 884627840.0000 - mean_squared_error: 884627840.0000 - val_loss: 1035195776.0000 - val_mean_squared_error: 1035195776.0000\n",
      "Epoch 66/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 933025920.0000 - mean_squared_error: 933025920.0000 - val_loss: 1047848384.0000 - val_mean_squared_error: 1047848384.0000\n",
      "Epoch 67/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 890003904.0000 - mean_squared_error: 890003904.0000 - val_loss: 1085785856.0000 - val_mean_squared_error: 1085785856.0000\n",
      "Epoch 68/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 888374016.0000 - mean_squared_error: 888374016.0000 - val_loss: 1070206784.0000 - val_mean_squared_error: 1070206784.0000\n",
      "Epoch 69/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 880323328.0000 - mean_squared_error: 880323328.0000 - val_loss: 1140158720.0000 - val_mean_squared_error: 1140158720.0000\n",
      "Epoch 70/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 898344576.0000 - mean_squared_error: 898344576.0000 - val_loss: 1056746112.0000 - val_mean_squared_error: 1056746112.0000\n",
      "Epoch 71/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 888198592.0000 - mean_squared_error: 888198592.0000 - val_loss: 998420480.0000 - val_mean_squared_error: 998420480.0000\n",
      "Epoch 72/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 869652800.0000 - mean_squared_error: 869652800.0000 - val_loss: 1244897408.0000 - val_mean_squared_error: 1244897408.0000\n",
      "Epoch 73/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 879847808.0000 - mean_squared_error: 879847808.0000 - val_loss: 1209293056.0000 - val_mean_squared_error: 1209293056.0000\n",
      "Epoch 74/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 868080768.0000 - mean_squared_error: 868080768.0000 - val_loss: 956921280.0000 - val_mean_squared_error: 956921280.0000\n",
      "Epoch 75/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 881113920.0000 - mean_squared_error: 881113920.0000 - val_loss: 1256384384.0000 - val_mean_squared_error: 1256384384.0000\n",
      "Epoch 76/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 854615936.0000 - mean_squared_error: 854615936.0000 - val_loss: 1042127168.0000 - val_mean_squared_error: 1042127168.0000\n",
      "Epoch 77/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 841024512.0000 - mean_squared_error: 841024512.0000 - val_loss: 989628480.0000 - val_mean_squared_error: 989628480.0000\n",
      "Epoch 78/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 857355456.0000 - mean_squared_error: 857355456.0000 - val_loss: 1076560000.0000 - val_mean_squared_error: 1076560000.0000\n",
      "Epoch 79/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 851279360.0000 - mean_squared_error: 851279360.0000 - val_loss: 1172616576.0000 - val_mean_squared_error: 1172616576.0000\n",
      "Epoch 80/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 848234752.0000 - mean_squared_error: 848234752.0000 - val_loss: 1055308032.0000 - val_mean_squared_error: 1055308032.0000\n",
      "Epoch 81/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 819817408.0000 - mean_squared_error: 819817408.0000 - val_loss: 974635584.0000 - val_mean_squared_error: 974635584.0000\n",
      "Epoch 82/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 818719936.0000 - mean_squared_error: 818719936.0000 - val_loss: 979937856.0000 - val_mean_squared_error: 979937856.0000\n",
      "Epoch 83/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 831040832.0000 - mean_squared_error: 831040832.0000 - val_loss: 959585536.0000 - val_mean_squared_error: 959585536.0000\n",
      "Epoch 84/100\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 817518656.0000 - mean_squared_error: 817518656.0000 - val_loss: 997301760.0000 - val_mean_squared_error: 997301760.0000\n",
      "Epoch 85/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 808683584.0000 - mean_squared_error: 808683584.0000 - val_loss: 933257600.0000 - val_mean_squared_error: 933257600.0000\n",
      "Epoch 86/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 813707200.0000 - mean_squared_error: 813707200.0000 - val_loss: 962654080.0000 - val_mean_squared_error: 962654080.0000\n",
      "Epoch 87/100\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 794361152.0000 - mean_squared_error: 794361152.0000 - val_loss: 1049631488.0000 - val_mean_squared_error: 1049631488.0000\n",
      "Epoch 88/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 832849280.0000 - mean_squared_error: 832849280.0000 - val_loss: 935156992.0000 - val_mean_squared_error: 935156992.0000\n",
      "Epoch 89/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 778264640.0000 - mean_squared_error: 778264640.0000 - val_loss: 934348544.0000 - val_mean_squared_error: 934348544.0000\n",
      "Epoch 90/100\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 785797312.0000 - mean_squared_error: 785797312.0000 - val_loss: 955343424.0000 - val_mean_squared_error: 955343424.0000\n",
      "Epoch 91/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 805661824.0000 - mean_squared_error: 805661824.0000 - val_loss: 970691712.0000 - val_mean_squared_error: 970691712.0000\n",
      "Epoch 92/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 806071040.0000 - mean_squared_error: 806071040.0000 - val_loss: 925232704.0000 - val_mean_squared_error: 925232704.0000\n",
      "Epoch 93/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 757301568.0000 - mean_squared_error: 757301568.0000 - val_loss: 906380800.0000 - val_mean_squared_error: 906380800.0000\n",
      "Epoch 94/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 775318400.0000 - mean_squared_error: 775318400.0000 - val_loss: 994926208.0000 - val_mean_squared_error: 994926208.0000\n",
      "Epoch 95/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 788373952.0000 - mean_squared_error: 788373952.0000 - val_loss: 1058005376.0000 - val_mean_squared_error: 1058005376.0000\n",
      "Epoch 96/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 781400896.0000 - mean_squared_error: 781400896.0000 - val_loss: 951149248.0000 - val_mean_squared_error: 951149248.0000\n",
      "Epoch 97/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 754155200.0000 - mean_squared_error: 754155200.0000 - val_loss: 860938496.0000 - val_mean_squared_error: 860938496.0000\n",
      "Epoch 98/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 752653248.0000 - mean_squared_error: 752653248.0000 - val_loss: 927505536.0000 - val_mean_squared_error: 927505536.0000\n",
      "Epoch 99/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 759385984.0000 - mean_squared_error: 759385984.0000 - val_loss: 875164544.0000 - val_mean_squared_error: 875164544.0000\n",
      "Epoch 100/100\n",
      "979/979 [==============================] - 8s 8ms/step - loss: 769744512.0000 - mean_squared_error: 769744512.0000 - val_loss: 907630272.0000 - val_mean_squared_error: 907630272.0000\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_features, train_labels,epochs=100, validation_split=0.2)\n",
    "\n",
    "val_mean_squared_error_per_epoch = history.history['val_mean_squared_error']\n",
    "best_epoch = val_mean_squared_error_per_epoch.index(max(val_mean_squared_error_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 5237950464.0000 - mean_squared_error: 5237950464.0000 - val_loss: 2023285248.0000 - val_mean_squared_error: 2023285248.0000\n",
      "Epoch 2/1000\n",
      "979/979 [==============================] - 9s 10ms/step - loss: 1954282880.0000 - mean_squared_error: 1954282880.0000 - val_loss: 1642911232.0000 - val_mean_squared_error: 1642911232.0000\n",
      "Epoch 3/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1485847936.0000 - mean_squared_error: 1485847936.0000 - val_loss: 1422547200.0000 - val_mean_squared_error: 1422547200.0000\n",
      "Epoch 4/1000\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 1338873472.0000 - mean_squared_error: 1338873472.0000 - val_loss: 1327345152.0000 - val_mean_squared_error: 1327345152.0000\n",
      "Epoch 5/1000\n",
      "979/979 [==============================] - 9s 9ms/step - loss: 1237288064.0000 - mean_squared_error: 1237288064.0000 - val_loss: 1227312512.0000 - val_mean_squared_error: 1227312512.0000\n",
      "Epoch 6/1000\n",
      "979/979 [==============================] - 10s 10ms/step - loss: 1178773120.0000 - mean_squared_error: 1178773120.0000 - val_loss: 1102721152.0000 - val_mean_squared_error: 1102721152.0000\n",
      "Epoch 7/1000\n",
      "194/979 [====>.........................] - ETA: 7s - loss: 1182854912.0000 - mean_squared_error: 1182854912.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25892\\3660668910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             metrics=['mean_squared_error'])\n\u001b[0;32m     18\u001b[0m history=model.fit(train_features, train_labels, epochs=1000, validation_split=0.2,\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\Users\\sakkosjo\\Anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = keras.Sequential(normalizer)\n",
    "#l2r = hp.Float(\"L2_rate\", min_value=1e-4, max_value=5e-1, sampling=\"log\")\n",
    "#,kernel_regularizer=keras.regularizers.l2(l2r)\n",
    "# Tune the number of units in the first Dense layer\n",
    "# Choose an optimal value between 32-512\n",
    "model.add(keras.layers.Dense(units=256, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "#keras.layers.Dropout(hp.Float(\"Dropout\", min_value=0, max_value=5e-1, sampling='linear')),\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Tune the learning rate for the optimizer\n",
    "#learning_rate = hp.Choice('Learning_Rate', values=[5e-1, 3e-1, 1e-1,1e-2])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=.07),\n",
    "            loss='mean_squared_error',\n",
    "            metrics=['mean_squared_error'])\n",
    "history=model.fit(train_features, train_labels, epochs=1000, validation_split=0.2,\n",
    "callbacks=[stop_early]\n",
    ")\n",
    "_, mse = model.evaluate(test_features, test_labels)\n",
    "test_predictions  = model.predict(test_features).flatten()\n",
    "r2=r2_score(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306/306 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions  = model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "\n",
    "lims = [0, test_labels.max()]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9425615237485384"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_labels, test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26969b46610202d946b3f9728b0f2ca828b45b6a858b4117f98f4654f0451e5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
